{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import subprocess\n",
    "import json\n",
    "import util as prep\n",
    "from IPython import get_ipython\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: coldata prep, validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "\n",
    "DATA_PREP_DIR = Path(get_ipython().getoutput(\"pwd\")[0]).parent\n",
    "BASE_DIR = DATA_PREP_DIR.parent\n",
    "DATA_URLS_PATH = DATA_PREP_DIR / \"geo_data_urls.json\"\n",
    "METADATA_DIR = DATA_PREP_DIR / \"metadata\"\n",
    "DATA_DIR = BASE_DIR / \"data\"\n",
    "CELFILE_DIR = DATA_DIR / \"cel_files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download GEO data\n",
    "\n",
    "# Create CEL file dir if it doesn't exist\n",
    "CELFILE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Open JSON file with data urls\n",
    "with open(DATA_URLS_PATH, \"r\") as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "# Download GEO data\n",
    "for key, url in data.items():\n",
    "    print(f\"Downloading file from: {url}\")\n",
    "    tar_path = CELFILE_DIR / (key + \".tar\")\n",
    "    prep.download_file(url, tar_path)\n",
    "    print(f\"Untarring and unzipping file at: {tar_path}\")\n",
    "    prep.untar_and_unzip(tar_path, CELFILE_DIR / key, delete_archive=True)\n",
    "\n",
    "print(\"All files downloaded and extracted successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get counts and sample conditions\n",
    "\n",
    "counts_dir = DATA_DIR / \"all\"\n",
    "counts_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "probe_maps_path = METADATA_DIR / \"probe_maps\"\n",
    "\n",
    "preprocessing_script = str(DATA_PREP_DIR / \"rma_counts.r\")\n",
    "cmd = [\"Rscript\", preprocessing_script, str(CELFILE_DIR), str(counts_dir)]\n",
    "subprocess.run(cmd)\n",
    "\n",
    "prep.prep_geo_counts(counts_dir, probe_maps_path, METADATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unify counts\n",
    "\n",
    "counts_paths = counts_dir.glob(\"*.tsv\")\n",
    "unified_counts_path = counts_dir / \"all_phases_all_genes_counts.tsv\"\n",
    "\n",
    "dataframes = [pd.read_csv(filepath, index_col=0, delimiter='\\t') for filepath in counts_paths]\n",
    "merged_counts_df = pd.concat(dataframes, axis=1)\n",
    "\n",
    "# Check if there are any missing values in the merged dataframe\n",
    "if merged_counts_df.isnull().any().any():\n",
    "    print('There are missing values in the merged dataframe.')\n",
    "\n",
    "# save merged dataframe to tsv\n",
    "merged_counts_df.to_csv(unified_counts_path, sep='\\t')\n",
    "\n",
    "# delete individual counts files\n",
    "for filepath in counts_paths:\n",
    "    filepath.unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unify coldata and add column for batch number\n",
    "\n",
    "coldata_paths = counts_dir.glob(\"*_coldata.tsv\")\n",
    "unified_coldata_path = counts_dir / \"all_phases_all_genes_coldata.tsv\"\n",
    "\n",
    "\"\"\" Batches:\n",
    "    1. GSE4888 (reference batch)\n",
    "    2. GSE6364\n",
    "    3. GSE51981\n",
    "    4. GSE29981\n",
    "\"\"\"\n",
    "\n",
    "coldata_paths_by_batch = {}\n",
    "\n",
    "for path in coldata_paths:\n",
    "    if \"gse4888\" in str(path).lower():\n",
    "        coldata_paths_by_batch[1] = path\n",
    "    elif \"gse6364\" in str(path).lower():\n",
    "        coldata_paths_by_batch[2] = path\n",
    "    elif \"gse51981\" in str(path).lower():\n",
    "        coldata_paths_by_batch[3] = path\n",
    "    elif \"gse29981\" in str(path).lower():\n",
    "        coldata_paths_by_batch[4] = path\n",
    "\n",
    "batch_dfs = {\n",
    "    batch: pd.read_csv(path, index_col=0, delimiter='\\t')\n",
    "    for batch, path in coldata_paths_by_batch.items()\n",
    "}\n",
    "\n",
    "merged_coldata_df = pd.concat([batch_dfs[batch] for batch in sorted(batch_dfs.keys())], axis=0)\n",
    "\n",
    "# Check if there are any missing values in the merged dataframe\n",
    "if merged_coldata_df.isnull().any().any():\n",
    "    print('There are missing values in the merged dataframe.')\n",
    "\n",
    "# save merged dataframe to tsv\n",
    "merged_coldata_df.to_csv(counts_dir / \"all_phases_all_genes_coldata.tsv\", sep='\\t')\n",
    "\n",
    "# delete individual coldata files\n",
    "for filepath in coldata_paths:\n",
    "    filepath.unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch correction\n",
    "\n",
    "reference_level = \"healthy\"\n",
    "contrast_level = \"endometriosis\"\n",
    "\n",
    "bc_script = str(DATA_PREP_DIR / \"batch_correction.r\")\n",
    "\n",
    "cmd = [\"Rscript\", bc_script, str(unified_counts_path), str(unified_coldata_path), str(counts_dir)]\n",
    "subprocess.run(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create filtered counts for all matrisome and core matrisome genes\n",
    "with open(METADATA_DIR / \"core_matrisome_genes.json\", 'r') as json_file:\n",
    "    matrisome_core_genes = json.load(json_file)['symbols']\n",
    "\n",
    "with open(METADATA_DIR / \"all_matrisome_genes.json\", 'r') as json_file:\n",
    "    matrisome_all_genes = json.load(json_file)['symbols']\n",
    "\n",
    "counts_df = pd.read_csv(unified_counts_path, sep='\\t')\n",
    "\n",
    "core_matrisome_counts_df = counts_df[counts_df['hgnc_symbol'].isin(matrisome_core_genes)]\n",
    "core_matrisome_counts_df = core_matrisome_counts_df.groupby('hgnc_symbol').mean().reset_index()\n",
    "core_counts_path = DATA_DIR / \"all\" / \"all_phases_core_matrisome_counts.tsv\"\n",
    "core_matrisome_counts_df.to_csv(core_counts_path, sep='\\t', index=False)\n",
    "\n",
    "all_matrisome_counts_df = counts_df[counts_df['hgnc_symbol'].isin(matrisome_all_genes)]\n",
    "all_matrisome_counts_df = all_matrisome_counts_df.groupby('hgnc_symbol').mean().reset_index()\n",
    "all_counts_path = DATA_DIR / \"all\" / \"all_phases_all_matrisome_counts.tsv\"\n",
    "all_matrisome_counts_df.to_csv(all_counts_path, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate phases\n",
    "\n",
    "phases = [\n",
    "    \"all_phases\",\n",
    "    \"early_secretory\",\n",
    "    \"mid_secretory\",\n",
    "    \"proliferative\"\n",
    "]\n",
    "\n",
    "all_phase_counts_fp_per_gene_set = {\n",
    "    \"all_genes\": DATA_DIR / \"all\" / \"all_phases_all_genes_counts.tsv\",\n",
    "    \"all_matrisome\": DATA_DIR / \"all\" / \"all_phases_all_matrisome_counts.tsv\",\n",
    "    \"core_matrisome\": DATA_DIR / \"all\" / \"all_phases_core_matrisome_counts.tsv\"\n",
    "}\n",
    "\n",
    "for gene_set in all_phase_counts_fp_per_gene_set:\n",
    "    all_phase_counts_fp = all_phase_counts_fp_per_gene_set[gene_set]\n",
    "    all_phase_counts_df = pd.read_csv(all_phase_counts_fp, sep='\\t')\n",
    "\n",
    "    for phase in phases:\n",
    "        coldata_fp = DATA_DIR / \"all\" / f\"{phase}_coldata.tsv\"\n",
    "        coldata_df = pd.read_csv(coldata_fp, sep='\\t')\n",
    "        sample_names = coldata_df['sample_name'].tolist()\n",
    "        sample_names.insert(0, \"hgnc_symbol\")\n",
    "        filtered_counts_df = all_phase_counts_df[sample_names]\n",
    "        counts_fp = str(all_phase_counts_fp).replace(\"all_phases\", phase)\n",
    "        filtered_counts_df.to_csv(counts_fp, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Set aside 45 samples for validation (24 healthy, 21 endometriosis) and separate fit/test sets.\n",
    "\n",
    "The test set contains the 45 validation samples, and the fit set contains all other samples.\n",
    "\"\"\"\n",
    "\n",
    "n_healthy = 24\n",
    "n_endometriosis = 21\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tissue-model-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
